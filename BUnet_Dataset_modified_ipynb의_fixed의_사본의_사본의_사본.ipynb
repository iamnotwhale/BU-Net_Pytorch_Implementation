{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamnotwhale/BU-Net_Pytorch_Implementation/blob/heoneyzi/BUnet_Dataset_modified_ipynb%EC%9D%98_fixed%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iM2NlT_VjlzW",
        "outputId": "6a5e7b33-f6d5-42ab-b20b-e74fe2a29163"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XbQsZqm07eIM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "import os\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class Custom2DBraTSDataset(Dataset):\n",
        "    def __init__(self, data_dir, modality):\n",
        "        self.data_dir = data_dir\n",
        "        self.modality = modality\n",
        "        self.patient_ids = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "\n",
        "        # Initialize lists to store slices\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        # Iterate through patients and load slices\n",
        "        for patient_id in self.patient_ids:\n",
        "            patient_path = os.path.join(self.data_dir, patient_id)\n",
        "\n",
        "            # Load image and label volumes\n",
        "            image = nib.load(os.path.join(patient_path, f'{patient_id}_{self.modality}.nii.gz')).get_fdata()\n",
        "            label = nib.load(os.path.join(patient_path, f'{patient_id}_seg.nii.gz')).get_fdata()\n",
        "\n",
        "            # Append all slices to the list\n",
        "            for slice_idx in range(image.shape[2] // 2 - 20, image.shape[2] // 2 + 20):\n",
        "                image_slice = image[:, :, slice_idx]\n",
        "                label_slice = label[:, :, slice_idx]\n",
        "\n",
        "                # Convert to torch tensor and add channel dimension for image\n",
        "                image_tensor = torch.tensor(image_slice, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
        "                # rgb_image_tensor = torch.cat((image_tensor, image_tensor, image_tensor), dim=0)\n",
        "                label_tensor = torch.tensor(label_slice, dtype=torch.long)\n",
        "\n",
        "                self.images.append(image_tensor)\n",
        "                self.labels.append(label_tensor)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        return image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "5vb8AeqILIIY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/BraTS_2018_Train_LGG' # put the directory of data\n",
        "modalities = ['t1', 't1ce', 't2', 'flair']"
      ],
      "metadata": {
        "id": "gJOPgy47LOFl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t1_dataset = Custom2DBraTSDataset(data_dir=data_dir, modality='t1')\n",
        "t2_dataset = Custom2DBraTSDataset(data_dir=data_dir, modality='t2')\n",
        "t1ce_dataset = Custom2DBraTSDataset(data_dir=data_dir, modality='t1ce')\n",
        "flair_dataset = Custom2DBraTSDataset(data_dir=data_dir, modality='flair')"
      ],
      "metadata": {
        "id": "ykDnMRiULOxV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
        "# 모든 데이터셋을 하나로 합치기\n",
        "combined_dataset = ConcatDataset([t1_dataset, t2_dataset, t1ce_dataset, flair_dataset])\n",
        "\n",
        "# 데이터셋 길이 확인 및 DataLoader 설정\n",
        "print(f\"Combined dataset length: {len(combined_dataset)}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xFDPBQtRiVe",
        "outputId": "cc7ed7d7-ef4d-42a1-d704-6388cd2c9c02"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined dataset length: 1120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# 전체 데이터셋 길이\n",
        "dataset_size = len(combined_dataset)\n",
        "\n",
        "# 훈련 데이터셋과 검증 데이터셋 사이즈 결정 (예: 75% 훈련, 25% 검증)\n",
        "train_size = int(0.75 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# 데이터셋을 무작위로 훈련 및 검증 세트로 분할\n",
        "train_dataset, val_dataset = random_split(combined_dataset, [train_size, val_size])\n",
        "\n",
        "# 각 데이터셋에 대한 DataLoader 설정\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
        "\n",
        "# 확인용 출력\n",
        "print(f\"Training dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SuiprZtqZ50v",
        "outputId": "d983f4a9-0b97-4dde-d07e-3e44a5dd0d5e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset size: 840\n",
            "Validation dataset size: 280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataloader:\n",
        "    print(images.shape, images)  # 출력: [batch_size, 1, D, H, W]\n",
        "    print(labels.shape, labels)  # 출력: [batch_size, D, H, W]\n",
        "    break"
      ],
      "metadata": {
        "id": "AuI-Oe3MvKkI",
        "outputId": "f61f74b3-3ce3-4069-a816-10c05da22232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 1, 240, 240]) tensor([[[[-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231],\n",
            "          [-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231],\n",
            "          [-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231],\n",
            "          ...,\n",
            "          [-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231],\n",
            "          [-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231],\n",
            "          [-0.4231, -0.4231, -0.4231,  ..., -0.4231, -0.4231, -0.4231]]],\n",
            "\n",
            "\n",
            "        [[[-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765],\n",
            "          [-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765],\n",
            "          [-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765],\n",
            "          ...,\n",
            "          [-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765],\n",
            "          [-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765],\n",
            "          [-0.4765, -0.4765, -0.4765,  ..., -0.4765, -0.4765, -0.4765]]],\n",
            "\n",
            "\n",
            "        [[[-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424],\n",
            "          [-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424],\n",
            "          [-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424],\n",
            "          ...,\n",
            "          [-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424],\n",
            "          [-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424],\n",
            "          [-0.4424, -0.4424, -0.4424,  ..., -0.4424, -0.4424, -0.4424]]],\n",
            "\n",
            "\n",
            "        [[[-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396],\n",
            "          [-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396],\n",
            "          [-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396],\n",
            "          ...,\n",
            "          [-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396],\n",
            "          [-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396],\n",
            "          [-0.4396, -0.4396, -0.4396,  ..., -0.4396, -0.4396, -0.4396]]]])\n",
            "torch.Size([4, 240, 240]) tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]],\n",
            "\n",
            "        [[0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         ...,\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0],\n",
            "         [0, 0, 0,  ..., 0, 0, 0]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class WC_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(WC_Block, self).__init__()\n",
        "\n",
        "        self.split_conv_x1_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(15, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x1_2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=(1, 15)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x2_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 15)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x2_2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=(15, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.conv_sum = nn.Conv2d(2* out_channels, out_channels, 3, padding=1)\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        split_conv_x1 = self.split_conv_x1_1(x)\n",
        "        split_conv_x1 = self.split_conv_x1_2(split_conv_x1)\n",
        "        split_conv_x2 = self.split_conv_x2_1(x)\n",
        "        split_conv_x2 = self.split_conv_x2_2(split_conv_x2)\n",
        "        x = torch.cat([split_conv_x1, split_conv_x2],dim=1)\n",
        "        x = self.conv_sum(x)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class BU_net(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(BU_net, self).__init__()\n",
        "        self.conv1 = DoubleConv(in_channels, 64)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = DoubleConv(64, 128)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv3 = DoubleConv(128, 256)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv4 = DoubleConv(256, 512)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.WC = WC_Block(512, 1024)\n",
        "        self.bottleneck = nn.Sequential(\n",
        "            nn.Conv2d(1024, 1024, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
        "        self.iconv4 = DoubleConv(1024, 512)\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.iconv3 = DoubleConv(512, 256)\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.iconv2 = DoubleConv(256, 128)\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.iconv1 = DoubleConv(128, 64)\n",
        "\n",
        "        self.outconv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv1 = self.conv1(x)\n",
        "        pool1 = self.pool1(conv1)\n",
        "        conv2 = self.conv2(pool1)\n",
        "        pool2 = self.pool2(conv2)\n",
        "        conv3 = self.conv3(pool2)\n",
        "        pool3 = self.pool3(conv3)\n",
        "        conv4 = self.conv4(pool3)\n",
        "        pool4 = self.pool4(conv4)\n",
        "\n",
        "        WC_block = self.WC(pool4)\n",
        "        bottleneck = self.bottleneck(WC_block)\n",
        "\n",
        "        upconv4 = self.upconv4(bottleneck)\n",
        "        upconv4 = F.interpolate(upconv4, size=conv4.shape[2:4])\n",
        "        cat4 = torch.cat((upconv4, conv4), dim=1)\n",
        "        iconv4 = self.iconv4(cat4)\n",
        "        upconv3 = self.upconv3(iconv4)\n",
        "        cat3 = torch.cat((upconv3, conv3), dim=1)\n",
        "        iconv3 = self.iconv3(cat3)\n",
        "        upconv2 = self.upconv2(iconv3)\n",
        "        cat2 = torch.cat((upconv2, conv2), dim=1)\n",
        "        iconv2 = self.iconv2(cat2)\n",
        "        upconv1 = self.upconv1(iconv2)\n",
        "        cat1 = torch.cat((upconv1, conv1), dim=1)\n",
        "        iconv1 = self.iconv1(cat1)\n",
        "\n",
        "        out = self.outconv(iconv1)\n",
        "        out = self.softmax(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "6iEyD0BJkKW7"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def compute_class_weight(target):\n",
        "    n, H, W = target.size()\n",
        "    class_weights = torch.zeros(n, H, W).to(target.device)\n",
        "    max_value = int(target.max().item())\n",
        "    for i in range(max_value + 1):\n",
        "        mask = (target == i).float()\n",
        "        class_weight = 1.0 / (mask.sum() + 1e-6)\n",
        "        class_weights += mask * class_weight\n",
        "    return class_weights\n",
        "\n",
        "def Dice_Loss_Coefficient(pred, target, smooth=1.):\n",
        "    n, c, H, W = pred.shape  # pred의 차원 정보를 가져옵니다.\n",
        "\n",
        "    # target을 pred의 크기인 H와 W로 리사이징\n",
        "    #target_resized = F.interpolate(target.float().unsqueeze(1), size=(H, W), mode='nearest').squeeze(1)\n",
        "    #target_resized = target_resized.unsqueeze(1).expand(n, c, H, W)  # [n, c, H, W]로 확장\n",
        "\n",
        "    # 클래스 가중치 계산을 위해 리사이징된 target 사용\n",
        "    target = target.long()\n",
        "    if target.dim() == 4:\n",
        "          target = target.squeeze(1)\n",
        "    target = target.expand(n, H, W)\n",
        "    weights = compute_class_weight(target)\n",
        "    #weights = compute_class_weight(target_resized[:, 0, :, :])  # 원래 target 대신 리사이징된 target 사용\n",
        "    weights = weights.unsqueeze(1).expand(n, c, H, W)  # [n, c, H, W]로 확장\n",
        "    target = target.unsqueeze(1).expand(n, c, H, W)\n",
        "    intersection = (pred * target * weights).sum(dim=2).sum(dim=2)\n",
        "    union = (weights * pred).sum(dim=2).sum(dim=2) + (weights * target).sum(dim=2).sum(dim=2)\n",
        "\n",
        "    loss = (1 - ((2. * intersection + smooth) / (union + smooth)))\n",
        "\n",
        "    return loss.mean()\n",
        "\n",
        "class Weighted_Cross_Entropy_Loss(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Weighted_Cross_Entropy_Loss, self).__init__()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "      n, c, H, W = pred.shape\n",
        "\n",
        "    # 클래스 레이블 검증 (0부터 c-1까지)\n",
        "      if (target.max() >= c) or (target.min() < 0):\n",
        "          #print(\"target tensor contains out-of-range values\")\n",
        "          target.clamp_(0, c-1)  # 잘못된 값 조정\n",
        "      if target.dim() == 4:\n",
        "          target = target.squeeze(1)\n",
        "\n",
        "      #target = F.interpolate(target.float().unsqueeze(1), size=(H, W), mode='nearest').unsqueeze(1)\n",
        "      target = target.long()\n",
        "\n",
        "      target = target.expand(n, H, W)\n",
        "      weights = compute_class_weight(target)\n",
        "      target = target.unsqueeze(1)\n",
        "      logp = F.log_softmax(pred, dim=1)\n",
        "      logp = torch.gather(logp, 1, target)\n",
        "      weighted_logp = (logp * weights.unsqueeze(1)).view(n, -1)\n",
        "      weighted_loss = weighted_logp.sum(1) / weights.view(n, -1).sum(1)\n",
        "      weighted_loss = -weighted_loss.mean()\n",
        "\n",
        "      return weighted_loss\n",
        "\n",
        "\n",
        "class BU_Net_Loss(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BU_Net_Loss, self).__init__()\n",
        "        self.cross_entropy_loss = Weighted_Cross_Entropy_Loss()\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        wce_loss = self.cross_entropy_loss(pred, target)\n",
        "        dice_loss = Dice_Loss_Coefficient(pred, target)\n",
        "        total_loss = wce_loss + dice_loss\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "DiaePBSyl2MS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "AFaMtiQGmmH1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(trainloader, model, optimizer, device):\n",
        "    model.train()\n",
        "    loss_criterion = BU_Net_Loss()  # Instantiate the loss object here\n",
        "    loss_criterion.to(device)       # Ensure the loss model is on the correct device\n",
        "    for i, (inputs, labels) in tqdm(enumerate(trainloader), total=len(trainloader)):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device=device, dtype=torch.int64)\n",
        "        inputs = inputs.float()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_criterion(outputs, labels)  # Correct usage of the loss function\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "Jqo4lpjUl3Yj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def accuracy_check(label, pred):\n",
        "    ims = [label, pred]\n",
        "    np_ims = []\n",
        "    for item in ims:\n",
        "        item = np.array(item)\n",
        "        np_ims.append(item)\n",
        "    compare = np.equal(np_ims[0], np_ims[1])\n",
        "    accuracy = np.sum(compare)\n",
        "    return accuracy / len(np_ims[0].flatten())\n",
        "\n",
        "def accuracy_check_for_batch(labels, preds, batch_size):\n",
        "    total_acc = 0\n",
        "    for i in range(batch_size):\n",
        "        total_acc += accuracy_check(labels[i], preds[i])\n",
        "    return total_acc/batch_size"
      ],
      "metadata": {
        "id": "Ek8N26xtmzNs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_loss_train(model, trainloader, loss, device):\n",
        "\n",
        "    model.eval()\n",
        "    total_acc = 0\n",
        "    total_loss = 0\n",
        "    for batch, (inputs, labels) in tqdm(enumerate(trainloader), total = len(trainloader)):\n",
        "        with torch.no_grad():\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device = device, dtype = torch.long)\n",
        "            inputs = inputs.float()\n",
        "\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = BU_Net_Loss()\n",
        "            loss_val = loss(outputs, labels)\n",
        "            outputs = np.transpose(outputs.cpu(), (0,2,3,1))\n",
        "            preds = torch.argmax(outputs, dim=3).float()\n",
        "            acc = accuracy_check_for_batch(labels.cpu(), preds.cpu(), inputs.size()[0])\n",
        "            total_acc += acc\n",
        "            total_loss += loss_val.cpu().item()\n",
        "    return total_acc/(batch+1), total_loss/(batch+1)"
      ],
      "metadata": {
        "id": "YdMlRDy9mk17"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val_model(model, valloader, loss, device):\n",
        "\n",
        "    total_val_loss = 0\n",
        "    total_val_acc = 0\n",
        "    n=0\n",
        "\n",
        "    for batch, (inputs, labels) in tqdm(enumerate(valloader), total = len(valloader)):\n",
        "        with torch.no_grad():\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device=device, dtype=torch.int64)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = BU_Net_Loss()\n",
        "            loss_value = loss(outputs, labels)\n",
        "\n",
        "            outputs = np.transpose(outputs.cpu(), (0, 2, 3, 1))\n",
        "            preds = torch.argmax(outputs, dim=3).float()\n",
        "\n",
        "            acc = accuracy_check_for_batch(labels.cpu(), preds.cpu(), inputs.size()[0])\n",
        "            total_val_acc += acc\n",
        "            total_val_loss += loss_value.cpu().item()\n",
        "\n",
        "\n",
        "\n",
        "    return total_val_acc/(batch+1), total_val_loss/(batch+1)"
      ],
      "metadata": {
        "id": "xx9_jq5Vmrfb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "learning_rate = 0.01\n",
        "momentum = 0.9\n",
        "epochs = 5\n",
        "\n",
        "# 모델 초기화\n",
        "model = BU_net(1, 4)\n",
        "print(model)\n",
        "\n",
        "criterion = BU_Net_Loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "model = model.to(device)\n",
        "history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
        "val_loader = val_dataloader"
      ],
      "metadata": {
        "id": "iafbGekRm0PC",
        "outputId": "822fb84a-d811-4e9d-b9c7-acfc03a5228f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BU_net(\n",
            "  (conv1): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv3): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv4): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (WC): WC_Block(\n",
            "    (split_conv_x1_1): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(15, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x1_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 15), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_1): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(1, 15), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(15, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (conv_sum): Conv2d(2048, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (batch_norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (bottleneck): Sequential(\n",
            "    (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "  )\n",
            "  (upconv4): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (iconv4): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv3): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (iconv3): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv2): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (iconv2): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (upconv1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (iconv1): DoubleConv(\n",
            "    (conv): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (outconv): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (softmax): Softmax(dim=1)\n",
            ")\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "UhoMhD9VabGL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training\")\n",
        "for epoch in range(epochs):\n",
        "    train_model(train_dataloader, model, optimizer, device)\n",
        "    train_acc, train_loss = get_loss_train(model, train_dataloader, BU_Net_Loss, device)\n",
        "    print(\"epoch\", epoch + 1, \"train loss : \", train_loss, \"train acc : \", train_acc)\n",
        "    val_loader = val_dataloader\n",
        "    val_acc, val_loss = val_model(model, val_loader, BU_Net_Loss, device)\n",
        "    print(\"epoch\", epoch + 1, \"val loss : \", val_loss, \"val acc : \", val_acc)\n",
        "\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "\n",
        "    if epoch % 5 == 0:\n",
        "        torch.save(model.state_dict(), f'./{str(epoch)}.pth')\n",
        "\n",
        "print('Finish Training')"
      ],
      "metadata": {
        "id": "kS1G_gYOnLDJ",
        "outputId": "12aaf0cb-8a90-4dab-e2e0-ee588cb1e79d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 1/210 [00:29<1:43:11, 29.63s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ee2ed82d5d8e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBU_Net_Loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train loss : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train acc : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-47b765b9fb81>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(trainloader, model, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Correct usage of the loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-44fa9b541907>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mcat2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupconv2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0miconv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mupconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miconv2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mcat1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupconv1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0miconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    950\u001b[0m             num_spatial_dims, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m    953\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             output_padding, self.groups, self.dilation)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}