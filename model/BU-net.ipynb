{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xsqh8UTuqGxV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b86bfb7-b80d-4546-b54a-d4c14094bbaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BUNet(\n",
            "  (encoder1): EncoderBlock(\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (encoder2): EncoderBlock(\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (encoder3): EncoderBlock(\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (encoder4): EncoderBlock(\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (bridge): ConvBlock(\n",
            "    (conv1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (res_block): RESBlock(\n",
            "    (split_conv_x1_1): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(15, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x1_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 15), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_1): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(13, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 13), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x3_1): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(11, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x3_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 11), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x4_1): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(9, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x4_2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 9), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (sum_conv_x1): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (sum_conv_x2): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (sum_conv_x3): Sequential(\n",
            "      (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (wc_block): WCBlock(\n",
            "    (split_conv_x1_1): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(15, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x1_2): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(1, 15), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_1): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(1, 15), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (split_conv_x2_2): Sequential(\n",
            "      (0): Conv2d(512, 512, kernel_size=(15, 1), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "    )\n",
            "    (batch_norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (decoder1): DecoderBlock(\n",
            "    (upconv): ConvTranspose2d(1536, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(1536, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder2): DecoderBlock(\n",
            "    (upconv): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder3): DecoderBlock(\n",
            "    (upconv): ConvTranspose2d(384, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder4): DecoderBlock(\n",
            "    (upconv): ConvTranspose2d(192, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "    (conv_blk): ConvBlock(\n",
            "      (conv1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (out_conv): Conv2d(64, 21, kernel_size=(1, 1), stride=(1, 1))\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class RESBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(RESBlock, self).__init__()\n",
        "\n",
        "        self.split_conv_x1_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(15, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x1_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 15)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.split_conv_x2_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(13, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x2_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 13)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.split_conv_x3_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(11, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x3_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 11)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.split_conv_x4_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(9, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x4_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 9)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.sum_conv_x1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.sum_conv_x2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.sum_conv_x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        init = x\n",
        "\n",
        "        split_conv_x1 = self.split_conv_x1_1(x)\n",
        "        split_conv_x1 = self.split_conv_x1_2(split_conv_x1)\n",
        "\n",
        "        split_conv_x2 = self.split_conv_x2_1(x)\n",
        "        split_conv_x2 = self.split_conv_x2_2(split_conv_x2)\n",
        "\n",
        "        split_conv_x3 = self.split_conv_x3_1(x)\n",
        "        split_conv_x3 = self.split_conv_x3_2(split_conv_x3)\n",
        "\n",
        "        split_conv_x4 = self.split_conv_x4_1(x)\n",
        "        split_conv_x4 = self.split_conv_x4_2(split_conv_x4)\n",
        "\n",
        "        x = torch.cat([init, split_conv_x1, split_conv_x2, split_conv_x3, split_conv_x4], dim=1)\n",
        "\n",
        "        x = self.sum_conv_x1(x)\n",
        "        x = self.sum_conv_x2(x)\n",
        "        x = self.sum_conv_x3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class WCBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(WCBlock, self).__init__()\n",
        "\n",
        "        self.split_conv_x1_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(15, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x1_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 15)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.split_conv_x2_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(1, 15)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "        self.split_conv_x2_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=(15, 1)),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "            )\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        split_conv_x1 = self.split_conv_x1_1(x)\n",
        "        split_conv_x1 = self.split_conv_x1_2(split_conv_x1)\n",
        "\n",
        "        split_conv_x2 = self.split_conv_x2_1(x)\n",
        "        split_conv_x2 = self.split_conv_x2_2(split_conv_x2)\n",
        "\n",
        "        x = torch.cat([split_conv_x1, split_conv_x2], dim=1)\n",
        "        x = self.batch_norm(x)\n",
        "        x = nn.ReLu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.conv_blk = ConvBlock(in_channels, out_channels)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_blk(x)\n",
        "        p = self.pool(x)\n",
        "        return x, p\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "        self.conv_blk = ConvBlock(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, skip):\n",
        "        x = self.upconv(x)\n",
        "        x = torch.cat([x, skip], dim=1)\n",
        "        x = self.conv_blk(x)\n",
        "        return x\n",
        "\n",
        "class BUNet(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(BUNet, self).__init__()\n",
        "        self.encoder1 = EncoderBlock(3, 64)\n",
        "        self.encoder2 = EncoderBlock(64, 128)\n",
        "        self.encoder3 = EncoderBlock(128, 256)\n",
        "        self.encoder4 = EncoderBlock(256, 512)\n",
        "\n",
        "        self.bridge = ConvBlock(512, 1024)\n",
        "\n",
        "        self.res_block = RESBlock(1024, 1024)\n",
        "        self.wc_block = WCBlock(512, 512)\n",
        "\n",
        "        self.decoder1 = DecoderBlock(1024 + 512, 512)\n",
        "        self.decoder2 = DecoderBlock(512 + 256, 256)\n",
        "        self.decoder3 = DecoderBlock(256 + 128, 128)\n",
        "        self.decoder4 = DecoderBlock(128 + 64, 64)\n",
        "\n",
        "        self.out_conv = nn.Conv2d(64, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        s1, p1 = self.encoder1(x)\n",
        "        s2, p2 = self.encoder2(p1)\n",
        "        s3, p3 = self.encoder3(p2)\n",
        "        s4, p4 = self.encoder4(p3)\n",
        "\n",
        "        b = self.bridge(p4)\n",
        "\n",
        "        wc = self.wc_block(s4)\n",
        "\n",
        "        res = self.res_block(b)\n",
        "\n",
        "        d1 = self.decoder1(res, wc)\n",
        "        d2 = self.decoder2(d1, s3)\n",
        "        d3 = self.decoder3(d2, s2)\n",
        "        d4 = self.decoder4(d3, s1)\n",
        "\n",
        "        outputs = self.out_conv(d4)\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        return outputs\n",
        "\n",
        "# 모델 초기화\n",
        "model = BUNet(n_classes=21)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. RES Block: 스킵 연결 중간에 위치.\n",
        "2. WC Block: 네 번째 다운 컨볼루션 결과를 처리."
      ],
      "metadata": {
        "id": "29KH_ILPqNsJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "주요 구현 사항\n",
        "1. RESBlock: Residual 블록으로, 스킵 연결 중간에 위치\n",
        "2. WCBlock: 네 번째 다운 컨볼루션 결과를 처리\n",
        "3. EncoderBlock: 기본적인 인코더 블록으로, 컨볼루션과 풀링 레이어를 포함\n",
        "4. DecoderBlock: 업샘플링과 컨볼루션을 포함한 디코더 블록\n",
        "5. BUNet: 전체 BU-Net 모델로, 인코더, 디코더, 브릿지, RES 블록, WC 블록을 포함\n",
        "- 필요한 경우 데이터셋과 학습 루프를 추가하여 training 할 수 있을듯 !"
      ],
      "metadata": {
        "id": "Zkcys0nHqSa3"
      }
    }
  ]
}